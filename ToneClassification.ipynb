{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tone Classification\n",
        "We're gonna try to classify the tone of audio samples... I'm not very experienced with classifying human speech, so for reference, I'm using these blog posts:  \n",
        "\n",
        "\n",
        "* https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
        "* https://towardsdatascience.com/audio-deep-learning-made-simple-part-2-why-mel-spectrograms-perform-better-aad889a93505\n",
        "* https://towardsdatascience.com/audio-deep-learning-made-simple-part-3-data-preparation-and-augmentation-24c6e1f6b52\n",
        "\n",
        "\n",
        "I'm not copy-pasting code or using the methods out-of-the-box unless otherwise noted in a comment, but I am following (most of) the methods in the blog post\n"
      ],
      "metadata": {
        "id": "HWjRd-xkYuxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_VualS_Xry2"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "import torchaudio\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Dataset\n",
        "This only has to run once."
      ],
      "metadata": {
        "id": "R3OhC3HdYLjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip data\n",
        "!unzip \"/content/drive/My Drive/Summer 2022/Misc/tone_perfect.zip\" -d \"/content/drive/My Drive/Summer 2022/Misc/tone_perfect\""
      ],
      "metadata": {
        "id": "WL38_L5jYWhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through data directory and load each piece of data\n",
        "# This prints out a ton of warnings which is very annoying\n",
        "DATAPATH = \"/content/drive/My Drive/Summer 2022/Misc/tone_perfect\"\n",
        "waveforms = []\n",
        "sample_rates = []\n",
        "fnames = []\n",
        "\n",
        "for fname in os.listdir(DATAPATH):\n",
        "  signal, sr = librosa.load(os.path.join(DATAPATH, fname))\n",
        "  waveforms.append(signal)\n",
        "  sample_rates.append(sr)\n",
        "  fnames.append(fname)"
      ],
      "metadata": {
        "id": "lKKKJbkRYSnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training samples: {0}\".format(len(fnames))) # Ok this is pretty small, doesn't take up much RAM. We'll just save it in a nice npz format\n",
        "print(set(sample_rates)) # and all of our sample rates are 22050! yay!\n",
        "print(set([w.shape for w in waveforms])) # lots of diferent lengths though... we can start by padding with silence, I guess\n",
        "print(set([len(w.shape) for w in waveforms])) # but no stereo, this is good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9o3iEwTZmZ_",
        "outputId": "eb412781-5194-4bc4-e080-7b12a7d86517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 2535\n",
            "{22050}\n",
            "{(24216,), (21912,), (22488,), (16728,), (11544,), (15000,), (18456,), (17304,), (12696,), (16152,), (10392,), (13848,), (8088,), (19608,), (10968,), (8664,), (5208,), (27672,), (25368,), (28248,), (25944,), (3262,), (6360,), (28824,), (23064,), (14424,), (17880,), (12120,), (15576,), (24792,), (19032,), (13272,), (7512,), (9816,), (20184,), (20760,), (23640,), (26520,), (9240,), (27096,), (21336,), (29400,), (6936,)}\n",
            "{1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cool, so we'll just make an npz with attributes: waves, tones, words, genders\n",
        "words = list(map(lambda x: x.split('_')[0][:-1], fnames))\n",
        "tones = list(map(lambda x: int(eval(x.split('_')[0][-1])), fnames))\n",
        "genders = list(map(lambda x: x.split('_')[1][:-1], fnames)) #either \"MV\" or \"FV\"\n",
        "\n",
        "np.savez(\"/content/drive/My Drive/Summer 2022/Misc/tone_data.npz\", words=words, tones=tones, genders=genders, waves=waveforms, allow_pickle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyz6Mc6BbdvP",
        "outputId": "1c4636fc-2ba2-434c-8a2e-f502c1d2891e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  val = np.asanyarray(val)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data for Training"
      ],
      "metadata": {
        "id": "2_tB10sDgFs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our prebuilt dataset\n",
        "ds = np.load(\"/content/drive/My Drive/Summer 2022/Misc/tone_data.npz\", allow_pickle=True)\n",
        "words = ds['words']\n",
        "tones = ds['tones']\n",
        "genders = ds['genders']\n",
        "waves = ds['waves']\n",
        "\n",
        "print('Unique words: {0}, unique tones: {1}'.format(len(set(words)), len(set(tones))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsZJKEXUddrS",
        "outputId": "528b672d-64b6-4ff7-d968-13c3b8f405a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words: 410, unique tones: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make our data nicely scaled\n",
        "print(np.min(waves[0]))\n",
        "print(np.max(waves[0]))\n",
        "print(waves[0].dtype)\n",
        "tones = np.asarray(tones) - 1\n",
        "\n",
        "# looks like waves are already in a nice format: scaled -1 to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmE-7V60hZnh",
        "outputId": "75215a5e-971f-49aa-8e00-369d208ef1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.824107\n",
            "0.9873464\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to decide on a max sequence length, we'll histogram the sequence lengths\n",
        "import seaborn as sns\n",
        "sns.histplot([x.shape[0] for x in waves])\n",
        "# looks like we'll go with 25k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "R3zrn6LmiZt3",
        "outputId": "605c3def-ff39-4f37-ea50-db89f378e65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc97db2ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchaudio import transforms\n",
        "# To start, we'll ignore the word and just pass wave as input, tone as output\n",
        "# We could do our preprocessing ahead of time... but if we want to do\n",
        "# data augmentation, we're going to have to do stuff at runtime, so I'll just make everything happen at runtime\n",
        "\n",
        "seq_len = 25000\n",
        "device = 'cuda:0'\n",
        "\n",
        "# spectrogram hyperparams\n",
        "top_db = 80\n",
        "n_mels = 64\n",
        "n_fft = 1024\n",
        "hop_length = None\n",
        "\n",
        "class ToneDS(Dataset):\n",
        "  def __init__(self, waves, tones):\n",
        "    self.waves = waves\n",
        "    self.tones = tones\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.tones.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    wave = self.waves[idx]\n",
        "\n",
        "    # padding/truncation\n",
        "    size = wave.shape[0]\n",
        "    wave = torch.tensor(wave)\n",
        "    if size>=seq_len:\n",
        "      wave = (wave[:seq_len])\n",
        "    \n",
        "    else:\n",
        "      wave = torch.cat([wave, torch.zeros(seq_len - size)], dim=0)\n",
        "\n",
        "    wave = wave.view(1, seq_len) # give it one channel\n",
        "    # if we ever to any data augmentation, it will go here\n",
        "\n",
        "\n",
        "    # Spectrogram time (COPIED FROM BLOG POST B/C I HAVE NO IDEA HOW THIS WORKS)\n",
        "    # SOMETIMES USING MFCC CAN BE BETTER APPARENTLY, BUT DIFFERENT SOURCES DISAGREE\n",
        "    # I'LL GO SIMPLE AND USE THE MEL SPECTROGRAM\n",
        "\n",
        "    # spec has shape [channel, n_mels, time], where channel is 1 in our case\n",
        "    spec = transforms.MelSpectrogram(22050, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)(wave)\n",
        "\n",
        "    # Convert to decibels\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "\n",
        "    return spec.to(device), self.tones[idx]"
      ],
      "metadata": {
        "id": "PRVegsIigap1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now actually construct the datasets and dataloaders\n",
        "dataset = ToneDS(waves, tones)\n",
        "\n",
        "# 80/20 trainval split\n",
        "train_size = int(len(dataset) * .8)\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "# batch shape is [batch_size, 1, 64, 49]"
      ],
      "metadata": {
        "id": "VG46HZ1_gE6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dl:\n",
        "  print(batch[0].shape)"
      ],
      "metadata": {
        "id": "7atqFq_govT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Architecture and Training"
      ],
      "metadata": {
        "id": "2WNOqLcFkvni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "\n",
        "def conv_block(filter_size, channels_in, channels_out, stride):\n",
        "  conv = nn.Conv2d(channels_in, channels_out, filter_size, stride=stride)\n",
        "  ac = nn.ReLU()\n",
        "  bn = nn.BatchNorm2d(channels_out)\n",
        "  return [conv, ac, bn]\n",
        "\n",
        "class ToneModel(nn.Module):\n",
        "  def __init__(self, num_outputs = 4):\n",
        "    super(ToneModel, self).__init__()\n",
        "\n",
        "    conv_blocks = [\n",
        "        conv_block(8, 1, 16, 2),\n",
        "        conv_block(6, 16, 32, 2),\n",
        "        conv_block(4, 32, 64, 1) \n",
        "    ]\n",
        "    layers = reduce(lambda x,y: x+y, conv_blocks, [])\n",
        "    layers.append(nn.Flatten())\n",
        "    layers.append(nn.Linear(2880, 64))\n",
        "    layers.append(nn.Tanh())\n",
        "    layers.append(nn.Linear(64, num_outputs))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "  def forward(self, inputs, return_logits = True):\n",
        "    logits = self.model(inputs)\n",
        "    if not return_logits:\n",
        "      return torch.softmax(logits,dim=-1)\n",
        "    else:\n",
        "      return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7LLqKNObkpX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Now for our trainloop\n",
        "def trainloop(model, dataloader, optimizer, loss_fnc, print_freq=10):\n",
        "  loss_sum = 0\n",
        "  for i, batch in tqdm(enumerate(dataloader)):\n",
        "    model.train()\n",
        "    inps = batch[0]\n",
        "    inps.to(device)\n",
        "    preds = model(inps)\n",
        "    labels = torch.eye(4)[batch[1]]\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fnc(preds, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_sum+=loss\n",
        "  return loss_sum\n",
        "\n",
        "model = ToneModel().to(device)\n",
        "loss_fnc = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), .001)\n",
        "\n",
        "for _ in range(15):\n",
        "  l = trainloop(model, train_dl, optimizer, loss_fnc)\n",
        "  print(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsP_1tZQpJ1S",
        "outputId": "1e799988-9932-447f-b454-e049655785c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:02, 46.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(52.1414, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 39.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.9757, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 38.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.0832, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:02, 42.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.8739, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:04, 31.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.0998, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:02, 42.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0944, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:02, 45.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 38.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.4171, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 37.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.2092, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 40.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0243, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:05, 25.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8011, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:04, 30.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:04, 29.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:02, 47.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:03, 40.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.9002, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ok now for validation...\n",
        "\n",
        "def valloop(model, dataloader):\n",
        "  outputs = []\n",
        "  labels = []\n",
        "  for i, batch in tqdm(enumerate(dataloader)):\n",
        "    model.eval()\n",
        "    inps = batch[0]\n",
        "    labels.append(batch[1].cpu().numpy())\n",
        "    inps.to(device)\n",
        "    preds = model(inps, return_logits=False)\n",
        "    outputs.append(preds.detach().cpu().numpy())\n",
        "  \n",
        "  yhat = np.argmax(np.concatenate(outputs),axis=-1)\n",
        "  labels = np.concatenate(labels)\n",
        "  return yhat, labels\n",
        "\n",
        "preds, labels = valloop(model, val_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC25dbDFtiVj",
        "outputId": "c98f5ba6-0bbb-4e56-ea6b-9546d5005e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:00, 27.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy: {0}\".format(accuracy_score(labels, preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XELOV58azbbm",
        "outputId": "ab71faf0-6683-4d09-ee89-36f20f25ca2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9704142011834319\n"
          ]
        }
      ]
    }
  ]
}